from transformers import pipeline, GPT2LMHeadModel, GPT2Tokenizer

# 1. Real-Time Speech Analysis and Sentiment Detection
sentiment_analyzer = pipeline("sentiment-analysis", model="distilbert-base-uncased-finetuned-sst-2-english", device=0)  # Explicitly setting model and device

def analyze_speech(speech):
    result = sentiment_analyzer(speech)
    sentiment = result[0]["label"]
    confidence = result[0]["score"]
    
    sentiment_insights = {
        "POSITIVE": "The customer seems enthusiastic. You can build on this energy.",
        "NEGATIVE": "The customer might have concerns. Try to understand their hesitation.",
        "NEUTRAL": "The response seems neutral. Engage them with more questions."
    }
    
    insight = sentiment_insights.get(sentiment, "Unable to analyze sentiment.")

    print("\n[Speech Analysis]")
    print(f"Detected Sentiment: {sentiment} (Confidence: {confidence:.2f})")
    print(f"Insight: {insight}")

    return sentiment, confidence


# 2. CRM-Integrated Product Recommendation System
crm_data = {
    "John Doe": {"past_purchases": ["Laptop"], "interests": ["Electronics", "Gaming"]},
    "Jane Smith": {"past_purchases": ["Running Shoes"], "interests": ["Fitness", "Sports"]}
}

def recommend_product(customer_name):
    print("\n[Product Recommendations]")
    if customer_name in crm_data:
        customer = crm_data[customer_name]
        recommendations = f"Based on your interests in {customer['interests']}, we recommend checking out Gaming Headsets and Laptops!"
    else:
        recommendations = f"Customer '{customer_name}' not found in CRM. Would you like to add them?"
    
    print(recommendations)
    return recommendations


# 3. Dynamic Question and Objection Handling Prompt Generator
model_name = "gpt2"
tokenizer = GPT2Tokenizer.from_pretrained(model_name)
model = GPT2LMHeadModel.from_pretrained(model_name)

# **Fix: Assign pad_token_id to eos_token_id**
tokenizer.pad_token = tokenizer.eos_token 

def generate_prompt(objection):
    print("\n[Objection Handling Prompt]")
    
    input_text = f"How to handle this objection: {objection}"
    input_ids = tokenizer.encode(input_text, return_tensors="pt")
    
    # **Fix: Explicitly set pad_token_id to tokenizer.eos_token_id**
    outputs = model.generate(input_ids, max_length=50, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)
    
    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)
    formatted_response = generated_text.replace(input_text, "").strip()
    
    print(f"Response: {formatted_response}")
    return formatted_response


# 4. Post-Call Summary and Insight Generation Module
def generate_summary(speech_transcript, sentiment):
    print("\n[Post-Call Summary]")
    
    summary_templates = {
        "POSITIVE": f"The customer showed interest in {speech_transcript}. Consider offering additional options.",
        "NEGATIVE": f"The customer had concerns about {speech_transcript}. Address objections and offer a solution.",
        "NEUTRAL": f"The discussion on {speech_transcript} was neutral. Engage the customer with more details."
    }
    
    summary = summary_templates.get(sentiment, "Unable to generate summary.")
    
    print(summary)
    return summary


# Main Flow
def ai_sales_assistant():
    print("Welcome to the AI-Driven Sales Assistant!")

    # Input customer name
    customer_name = input("\nEnter customer name: ")

    # Simulated sales call speech
    speech = input("\nEnter customer speech: ")

    # Step 1: Analyze Speech Sentiment
    sentiment, confidence = analyze_speech(speech)

    # Step 2: Provide Product Recommendations
    recommend_product(customer_name)

    # Step 3: Generate Question and Objection Handling Prompt
    generate_prompt(speech)

    # Step 4: Generate Post-Call Summary
    generate_summary(speech, sentiment)


# Run the assistant
ai_sales_assistant()
