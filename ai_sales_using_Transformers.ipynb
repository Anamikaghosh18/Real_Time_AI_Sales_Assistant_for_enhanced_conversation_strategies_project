{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OorxF6UA2Ire",
        "outputId": "88e21ced-003f-4c7c-d602-8d58b7b0cd77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the AI-Driven Sales Assistant!\n",
            "\n",
            "Enter customer name: Anamika\n",
            "\n",
            "Enter customer speech: english\n",
            "\n",
            "[Speech Analysis]\n",
            "Detected Sentiment: POSITIVE (Confidence: 1.00)\n",
            "Insight: The customer seems enthusiastic. You can build on this energy.\n",
            "\n",
            "[Product Recommendations]\n",
            "Customer 'Anamika' not found in CRM. Would you like to add them?\n",
            "\n",
            "[Objection Handling Prompt]\n",
            "Response: is not my native language. I'm not sure if it's a good idea to use it, but I'm sure it's a good idea to use it.\n",
            "\n",
            "I'm not sure if it's a\n",
            "\n",
            "[Post-Call Summary]\n",
            "The customer showed interest in english. Consider offering additional options.\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline, GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# 1. Real-Time Speech Analysis and Sentiment Detection\n",
        "sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\", device=0)  # Explicitly setting model and device\n",
        "\n",
        "def analyze_speech(speech):\n",
        "    result = sentiment_analyzer(speech)\n",
        "    sentiment = result[0][\"label\"]\n",
        "    confidence = result[0][\"score\"]\n",
        "\n",
        "    sentiment_insights = {\n",
        "        \"POSITIVE\": \"The customer seems enthusiastic. You can build on this energy.\",\n",
        "        \"NEGATIVE\": \"The customer might have concerns. Try to understand their hesitation.\",\n",
        "        \"NEUTRAL\": \"The response seems neutral. Engage them with more questions.\"\n",
        "    }\n",
        "\n",
        "    insight = sentiment_insights.get(sentiment, \"Unable to analyze sentiment.\")\n",
        "\n",
        "    print(\"\\n[Speech Analysis]\")\n",
        "    print(f\"Detected Sentiment: {sentiment} (Confidence: {confidence:.2f})\")\n",
        "    print(f\"Insight: {insight}\")\n",
        "\n",
        "    return sentiment, confidence\n",
        "\n",
        "\n",
        "# 2. CRM-Integrated Product Recommendation System\n",
        "crm_data = {\n",
        "    \"John Doe\": {\"past_purchases\": [\"Laptop\"], \"interests\": [\"Electronics\", \"Gaming\"]},\n",
        "    \"Jane Smith\": {\"past_purchases\": [\"Running Shoes\"], \"interests\": [\"Fitness\", \"Sports\"]}\n",
        "}\n",
        "\n",
        "def recommend_product(customer_name):\n",
        "    print(\"\\n[Product Recommendations]\")\n",
        "    if customer_name in crm_data:\n",
        "        customer = crm_data[customer_name]\n",
        "        recommendations = f\"Based on your interests in {customer['interests']}, we recommend checking out Gaming Headsets and Laptops!\"\n",
        "    else:\n",
        "        recommendations = f\"Customer '{customer_name}' not found in CRM. Would you like to add them?\"\n",
        "\n",
        "    print(recommendations)\n",
        "    return recommendations\n",
        "\n",
        "\n",
        "# 3. Dynamic Question and Objection Handling Prompt Generator\n",
        "model_name = \"gpt2\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "# **Fix: Assign pad_token_id to eos_token_id**\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "def generate_prompt(objection):\n",
        "    print(\"\\n[Objection Handling Prompt]\")\n",
        "\n",
        "    input_text = f\"How to handle this objection: {objection}\"\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "\n",
        "    # **Fix: Explicitly set pad_token_id to tokenizer.eos_token_id**\n",
        "    outputs = model.generate(input_ids, max_length=50, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    formatted_response = generated_text.replace(input_text, \"\").strip()\n",
        "\n",
        "    print(f\"Response: {formatted_response}\")\n",
        "    return formatted_response\n",
        "\n",
        "\n",
        "# 4. Post-Call Summary and Insight Generation Module\n",
        "def generate_summary(speech_transcript, sentiment):\n",
        "    print(\"\\n[Post-Call Summary]\")\n",
        "\n",
        "    summary_templates = {\n",
        "        \"POSITIVE\": f\"The customer showed interest in {speech_transcript}. Consider offering additional options.\",\n",
        "        \"NEGATIVE\": f\"The customer had concerns about {speech_transcript}. Address objections and offer a solution.\",\n",
        "        \"NEUTRAL\": f\"The discussion on {speech_transcript} was neutral. Engage the customer with more details.\"\n",
        "    }\n",
        "\n",
        "    summary = summary_templates.get(sentiment, \"Unable to generate summary.\")\n",
        "\n",
        "    print(summary)\n",
        "    return summary\n",
        "\n",
        "\n",
        "# Main Flow\n",
        "def ai_sales_assistant():\n",
        "    print(\"Welcome to the AI-Driven Sales Assistant!\")\n",
        "\n",
        "    # Input customer name\n",
        "    customer_name = input(\"\\nEnter customer name: \")\n",
        "\n",
        "    # Simulated sales call speech\n",
        "    speech = input(\"\\nEnter customer speech: \")\n",
        "\n",
        "    # Step 1: Analyze Speech Sentiment\n",
        "    sentiment, confidence = analyze_speech(speech)\n",
        "\n",
        "    # Step 2: Provide Product Recommendations\n",
        "    recommend_product(customer_name)\n",
        "\n",
        "    # Step 3: Generate Question and Objection Handling Prompt\n",
        "    generate_prompt(speech)\n",
        "\n",
        "    # Step 4: Generate Post-Call Summary\n",
        "    generate_summary(speech, sentiment)\n",
        "\n",
        "\n",
        "# Run the assistant\n",
        "ai_sales_assistant()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers torch"
      ],
      "metadata": {
        "id": "QMZMbAbjWMBa",
        "outputId": "7857885d-d41b-4c38-b682-5d5818557548",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Sentiment analysis pipeline\n",
        "sentiment_analyzer = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "def analyze_speech(speech):\n",
        "    result = sentiment_analyzer(speech)\n",
        "    sentiment = result[0][\"label\"]\n",
        "    confidence = result[0][\"score\"]\n",
        "    print(f\"Detected Sentiment: {sentiment} (Confidence: {confidence:.2f})\")\n",
        "    return sentiment, confidence\n",
        "\n",
        "# Example input\n",
        "speech = \"I'm very much sure that I want this product\"\n",
        "analyze_speech(speech)\n",
        "\n",
        "# Example speech inputs and sentiment analysis\n",
        "speech_examples = [\n",
        "    \"I'm not sure if I want this product. It seems too expensive.\",\n",
        "    \"This product is amazing! I can't wait to use it.\",\n",
        "    \"I'm really disappointed with the quality of this item.\",\n",
        "    \"Can you tell me more about this feature? It sounds interesting.\",\n",
        "    \"The price seems fair, but I still need to think about it.\",\n",
        "    \"I don't trust this brand based on my past experience.\",\n",
        "    \"Wow, this is exactly what I've been looking for!\",\n",
        "    \"I think I might go for a competitor's product instead.\",\n",
        "    \"I'm thrilled with the service I've received so far!\",\n",
        "    \"I'm feeling overwhelmed by the options. Can you simplify it for me?\"\n",
        "]\n",
        "\n",
        "# Analyze each speech input\n",
        "for speech in speech_examples:\n",
        "    print(f\"Analyzing: \\\"{speech}\\\"\")\n",
        "    analyze_speech(speech)\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "id": "2T59eGxtWwmq",
        "outputId": "7946c394-d861-445f-877f-da3f562102e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected Sentiment: POSITIVE (Confidence: 1.00)\n",
            "Analyzing: \"I'm not sure if I want this product. It seems too expensive.\"\n",
            "Detected Sentiment: NEGATIVE (Confidence: 1.00)\n",
            "--------------------------------------------------\n",
            "Analyzing: \"This product is amazing! I can't wait to use it.\"\n",
            "Detected Sentiment: POSITIVE (Confidence: 1.00)\n",
            "--------------------------------------------------\n",
            "Analyzing: \"I'm really disappointed with the quality of this item.\"\n",
            "Detected Sentiment: NEGATIVE (Confidence: 1.00)\n",
            "--------------------------------------------------\n",
            "Analyzing: \"Can you tell me more about this feature? It sounds interesting.\"\n",
            "Detected Sentiment: POSITIVE (Confidence: 1.00)\n",
            "--------------------------------------------------\n",
            "Analyzing: \"The price seems fair, but I still need to think about it.\"\n",
            "Detected Sentiment: NEGATIVE (Confidence: 0.50)\n",
            "--------------------------------------------------\n",
            "Analyzing: \"I don't trust this brand based on my past experience.\"\n",
            "Detected Sentiment: NEGATIVE (Confidence: 1.00)\n",
            "--------------------------------------------------\n",
            "Analyzing: \"Wow, this is exactly what I've been looking for!\"\n",
            "Detected Sentiment: POSITIVE (Confidence: 1.00)\n",
            "--------------------------------------------------\n",
            "Analyzing: \"I think I might go for a competitor's product instead.\"\n",
            "Detected Sentiment: NEGATIVE (Confidence: 1.00)\n",
            "--------------------------------------------------\n",
            "Analyzing: \"I'm thrilled with the service I've received so far!\"\n",
            "Detected Sentiment: POSITIVE (Confidence: 1.00)\n",
            "--------------------------------------------------\n",
            "Analyzing: \"I'm feeling overwhelmed by the options. Can you simplify it for me?\"\n",
            "Detected Sentiment: POSITIVE (Confidence: 0.70)\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mock CRM data\n",
        "crm_data = {\n",
        "    \"John Doe\": {\"past_purchases\": [\"Laptop\"], \"interests\": [\"Electronics\", \"Gaming\"]},\n",
        "    \"Jane Smith\": {\"past_purchases\": [\"Running Shoes\"], \"interests\": [\"Fitness\", \"Sports\"]}\n",
        "}\n",
        "\n",
        "def recommend_product(customer_name):\n",
        "    if customer_name in crm_data:\n",
        "        customer = crm_data[customer_name]\n",
        "        recommendations = f\"Based on your interests in {customer['interests']}, we recommend these products!\"\n",
        "        print(recommendations)\n",
        "    else:\n",
        "        print(\"Customer not found in CRM.\")\n",
        "    return recommendations\n",
        "\n",
        "# Example usage\n",
        "recommend_product(\"John Doe\")\n"
      ],
      "metadata": {
        "id": "Yr1UF4aqW2o2",
        "outputId": "5d8ed9b8-95cb-4d45-8eab-b07bb6a35e54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on your interests in ['Electronics', 'Gaming'], we recommend these products!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Based on your interests in ['Electronics', 'Gaming'], we recommend these products!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# Load pre-trained model and tokenizer\n",
        "model_name = \"gpt2\"  # Use GPT-3 in real implementation\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "def generate_prompt(objection):\n",
        "    input_text = f\"How to handle this objection: {objection}\"\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "    outputs = model.generate(input_ids, max_length=50, num_return_sequences=1)\n",
        "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    print(f\"Prompt: {generated_text}\")\n",
        "\n",
        "# Example usage\n",
        "objection = \"This product is too expensive.\"\n",
        "generate_prompt(objection)\n"
      ],
      "metadata": {
        "id": "51XOfKOmW4He",
        "outputId": "a3887456-cd3c-482f-dd39-03aee5bbae57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: How to handle this objection: This product is too expensive.\n",
            "\n",
            "The problem is that the price of this product is too high.\n",
            "\n",
            "The problem is that the price of this product is too high.\n",
            "\n",
            "The problem is that the price\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_summary(speech_transcript):\n",
        "    # Mock summary generator\n",
        "    summary = f\"Summary: Customer expressed concerns about pricing. Suggested offering a discount.\"\n",
        "    print(summary)\n",
        "    return summary\n",
        "\n",
        "# Example usage\n",
        "speech_transcript = \"The customer is worried about the cost of this product.\"\n",
        "generate_summary(speech_transcript)\n"
      ],
      "metadata": {
        "id": "t-mbqvnkW9Gq",
        "outputId": "085006b8-8751-49ea-d256-2f9669e3b4fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary: Customer expressed concerns about pricing. Suggested offering a discount.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Summary: Customer expressed concerns about pricing. Suggested offering a discount.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_summary(speech_transcript):\n",
        "    # Analyze the transcript and return a mock summary\n",
        "    if \"cost\" in speech_transcript or \"price\" in speech_transcript:\n",
        "        summary = \"Summary: Customer expressed concerns about pricing. Suggested offering a discount or explaining financing options.\"\n",
        "    elif \"delivery\" in speech_transcript or \"time\" in speech_transcript:\n",
        "        summary = \"Summary: Customer was concerned about delivery timelines. Recommended expediting shipping or providing a tracking option.\"\n",
        "    elif \"features\" in speech_transcript or \"functionality\" in speech_transcript:\n",
        "        summary = \"Summary: Customer had questions about product features. Suggested sharing a detailed brochure or demo.\"\n",
        "    elif \"comparison\" in speech_transcript or \"competitor\" in speech_transcript:\n",
        "        summary = \"Summary: Customer compared the product with a competitor. Highlighted unique selling points and value-added services.\"\n",
        "    elif \"support\" in speech_transcript or \"after-sales\" in speech_transcript:\n",
        "        summary = \"Summary: Customer inquired about after-sales support. Reassured with details about warranty and customer support services.\"\n",
        "    elif \"budget\" in speech_transcript or \"affordability\" in speech_transcript:\n",
        "        summary = \"Summary: Customer mentioned budget constraints. Suggested discussing payment plans or recommending a more affordable option.\"\n",
        "    elif \"quality\" in speech_transcript or \"reliability\" in speech_transcript:\n",
        "        summary = \"Summary: Customer was concerned about product quality. Shared testimonials and warranty information for reassurance.\"\n",
        "    else:\n",
        "        summary = \"Summary: General discussion about the product. No major concerns noted. Follow-up scheduled for further engagement.\"\n",
        "\n",
        "    print(summary)\n",
        "    return summary\n",
        "\n",
        "\n",
        "# Example Usage\n",
        "transcripts = [\n",
        "    \"The customer is worried about the cost of this product.\",\n",
        "    \"The customer is asking about the delivery timeline for the product.\",\n",
        "    \"The customer wants to know more about the features of the product.\",\n",
        "    \"The customer mentioned that a competitor's product is cheaper.\",\n",
        "    \"The customer is concerned about the after-sales support for this product.\",\n",
        "    \"The customer said they are working with a limited budget.\",\n",
        "    \"The customer raised concerns about the reliability of the product.\",\n",
        "    \"The customer asked general questions without specific objections.\"\n",
        "]\n",
        "\n",
        "for transcript in transcripts:\n",
        "    print(\"\\nCustomer Speech:\", transcript)\n",
        "    generate_summary(transcript)\n"
      ],
      "metadata": {
        "id": "DWUa5EO5XEzi",
        "outputId": "870e68e3-a8b2-492d-b044-28dfb05836ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Customer Speech: The customer is worried about the cost of this product.\n",
            "Summary: Customer expressed concerns about pricing. Suggested offering a discount or explaining financing options.\n",
            "\n",
            "Customer Speech: The customer is asking about the delivery timeline for the product.\n",
            "Summary: Customer was concerned about delivery timelines. Recommended expediting shipping or providing a tracking option.\n",
            "\n",
            "Customer Speech: The customer wants to know more about the features of the product.\n",
            "Summary: Customer had questions about product features. Suggested sharing a detailed brochure or demo.\n",
            "\n",
            "Customer Speech: The customer mentioned that a competitor's product is cheaper.\n",
            "Summary: Customer compared the product with a competitor. Highlighted unique selling points and value-added services.\n",
            "\n",
            "Customer Speech: The customer is concerned about the after-sales support for this product.\n",
            "Summary: Customer inquired about after-sales support. Reassured with details about warranty and customer support services.\n",
            "\n",
            "Customer Speech: The customer said they are working with a limited budget.\n",
            "Summary: Customer mentioned budget constraints. Suggested discussing payment plans or recommending a more affordable option.\n",
            "\n",
            "Customer Speech: The customer raised concerns about the reliability of the product.\n",
            "Summary: Customer was concerned about product quality. Shared testimonials and warranty information for reassurance.\n",
            "\n",
            "Customer Speech: The customer asked general questions without specific objections.\n",
            "Summary: General discussion about the product. No major concerns noted. Follow-up scheduled for further engagement.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# Load pre-trained model and tokenizer\n",
        "model_name = \"gpt2\"  # Replace with \"gpt-3\" or other advanced models in a real implementation\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "def generate_prompt(objection):\n",
        "    \"\"\"\n",
        "    Generates a response to handle customer objections based on the input objection.\n",
        "\n",
        "    Parameters:\n",
        "    objection (str): Customer's objection or concern.\n",
        "\n",
        "    Returns:\n",
        "    str: AI-generated response for handling the objection.\n",
        "    \"\"\"\n",
        "    input_text = f\"How to handle this objection: {objection}\"\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "    outputs = model.generate(input_ids, max_length=50, num_return_sequences=1, no_repeat_ngram_size=2)\n",
        "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    print(f\"\\nObjection: {objection}\")\n",
        "    print(f\"Prompt: {generated_text}\\n\")\n",
        "    return generated_text\n",
        "\n",
        "# Example objections\n",
        "objections = [\n",
        "    \"This product is too expensive.\",\n",
        "    \"I don't think I need this product.\",\n",
        "    \"I am worried about the quality of the product.\",\n",
        "    \"I don't have enough information to decide.\",\n",
        "    \"Your competitor offers a better price.\",\n",
        "    \"The delivery time is too long.\",\n",
        "    \"I am not sure this fits my needs.\",\n",
        "    \"I need to consult my team before deciding.\",\n",
        "    \"I’ve had a bad experience with similar products.\",\n",
        "    \"I don’t see the value in this product.\"\n",
        "]\n",
        "\n",
        "# Generate prompts for each objection\n",
        "for objection in objections:\n",
        "    generate_prompt(objection)\n"
      ],
      "metadata": {
        "id": "aixt7tPAXIEu",
        "outputId": "a5bf9c14-179f-4883-caa8-80556dc08cf1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Objection: This product is too expensive.\n",
            "Prompt: How to handle this objection: This product is too expensive.\n",
            "\n",
            "The problem is that the price of this product has been rising for years. The price is rising because of the fact that it is a product that is not only expensive, but also\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Objection: I don't think I need this product.\n",
            "Prompt: How to handle this objection: I don't think I need this product. I just want to know what it is.\n",
            "\n",
            "I'm not sure if I should have bought it. It's not a good product, and I'm sure it's\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Objection: I am worried about the quality of the product.\n",
            "Prompt: How to handle this objection: I am worried about the quality of the product. I have been using this product for about a year now and I can tell you that it is not as good as I expected. The only thing I would change is to\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Objection: I don't have enough information to decide.\n",
            "Prompt: How to handle this objection: I don't have enough information to decide.\n",
            "\n",
            "I'm not sure if this is a good idea or not. I'm sure that it's not a bad idea. But I think it is important to understand that\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Objection: Your competitor offers a better price.\n",
            "Prompt: How to handle this objection: Your competitor offers a better price.\n",
            "\n",
            "The problem is that you're not paying for the service. You're paying the price for it. And you can't afford to pay for a service that's not available to\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Objection: The delivery time is too long.\n",
            "Prompt: How to handle this objection: The delivery time is too long.\n",
            "\n",
            "The delivery times are too short. The time to deliver is not too fast. It is a long time. You can't get it to you. If you want to get\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Objection: I am not sure this fits my needs.\n",
            "Prompt: How to handle this objection: I am not sure this fits my needs. I have a lot of experience with the use of the word \"disgusting\" in the context of a sexual encounter. It is not a word that I use often,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Objection: I need to consult my team before deciding.\n",
            "Prompt: How to handle this objection: I need to consult my team before deciding.\n",
            "\n",
            "I'm not sure if this is a good idea or not. I'm sure that it's not a bad idea. But I don't think it is. It\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Objection: I’ve had a bad experience with similar products.\n",
            "Prompt: How to handle this objection: I’ve had a bad experience with similar products. I have tried many different brands, and none of them are as good as the one I bought.\n",
            "\n",
            "I have also tried a few different products, but\n",
            "\n",
            "\n",
            "Objection: I don’t see the value in this product.\n",
            "Prompt: How to handle this objection: I don’t see the value in this product. I‖ve been using it for a while now and I have never had any problems with it. It is a great product and it is very easy to\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mock CRM data\n",
        "crm_data = {\n",
        "    \"John Doe\": {\"past_purchases\": [\"Laptop\"], \"interests\": [\"Electronics\", \"Gaming\"]},\n",
        "    \"Jane Smith\": {\"past_purchases\": [\"Running Shoes\"], \"interests\": [\"Fitness\", \"Sports\"]},\n",
        "    \"Alice Johnson\": {\"past_purchases\": [\"Smartphone\"], \"interests\": [\"Photography\", \"Travel\"]},\n",
        "    \"Bob Brown\": {\"past_purchases\": [\"Kitchen Blender\"], \"interests\": [\"Cooking\", \"Health\"]},\n",
        "    \"Eve Davis\": {\"past_purchases\": [\"Smartwatch\"], \"interests\": [\"Tech\", \"Fitness\"]},\n",
        "}\n",
        "\n",
        "def recommend_product(customer_name):\n",
        "    \"\"\"\n",
        "    Recommends products to the customer based on their past purchases and interests.\n",
        "\n",
        "    Parameters:\n",
        "    customer_name (str): Name of the customer in CRM data.\n",
        "\n",
        "    Returns:\n",
        "    str: Product recommendation message.\n",
        "    \"\"\"\n",
        "    if customer_name in crm_data:\n",
        "        customer = crm_data[customer_name]\n",
        "        past_purchases = \", \".join(customer[\"past_purchases\"])\n",
        "        interests = \", \".join(customer[\"interests\"])\n",
        "        recommendations = (\n",
        "            f\"Hello {customer_name}, based on your past purchases ({past_purchases}) \"\n",
        "            f\"and interests in {interests}, we recommend the following products:\\n\"\n",
        "        )\n",
        "        # Mock recommendations based on interests\n",
        "        interest_based_products = {\n",
        "            \"Electronics\": [\"Gaming Headset\", \"Mechanical Keyboard\"],\n",
        "            \"Gaming\": [\"Gaming Console\", \"VR Headset\"],\n",
        "            \"Fitness\": [\"Yoga Mat\", \"Resistance Bands\"],\n",
        "            \"Sports\": [\"Football\", \"Tennis Racket\"],\n",
        "            \"Photography\": [\"DSLR Camera\", \"Tripod\"],\n",
        "            \"Travel\": [\"Travel Backpack\", \"Noise-Cancelling Headphones\"],\n",
        "            \"Cooking\": [\"Air Fryer\", \"Chef's Knife\"],\n",
        "            \"Health\": [\"Blender Bottles\", \"Vitamin Supplements\"],\n",
        "            \"Tech\": [\"Smart Home Devices\", \"Wireless Earbuds\"],\n",
        "        }\n",
        "        # Compile product suggestions\n",
        "        suggested_products = []\n",
        "        for interest in customer[\"interests\"]:\n",
        "            if interest in interest_based_products:\n",
        "                suggested_products.extend(interest_based_products[interest])\n",
        "        recommendations += \", \".join(suggested_products)\n",
        "        print(recommendations)\n",
        "    else:\n",
        "        recommendations = f\"Customer {customer_name} not found in CRM.\"\n",
        "        print(recommendations)\n",
        "    return recommendations\n",
        "\n",
        "# Example usage\n",
        "recommend_product(\"John Doe\")\n",
        "recommend_product(\"Jane Smith\")\n",
        "recommend_product(\"Alice Johnson\")\n",
        "recommend_product(\"Bob Brown\")\n",
        "recommend_product(\"Eve Davis\")\n"
      ],
      "metadata": {
        "id": "7Qc3RVq4XJbZ",
        "outputId": "5638a1b3-142a-4465-c37d-718243b9192d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello John Doe, based on your past purchases (Laptop) and interests in Electronics, Gaming, we recommend the following products:\n",
            "Gaming Headset, Mechanical Keyboard, Gaming Console, VR Headset\n",
            "Hello Jane Smith, based on your past purchases (Running Shoes) and interests in Fitness, Sports, we recommend the following products:\n",
            "Yoga Mat, Resistance Bands, Football, Tennis Racket\n",
            "Hello Alice Johnson, based on your past purchases (Smartphone) and interests in Photography, Travel, we recommend the following products:\n",
            "DSLR Camera, Tripod, Travel Backpack, Noise-Cancelling Headphones\n",
            "Hello Bob Brown, based on your past purchases (Kitchen Blender) and interests in Cooking, Health, we recommend the following products:\n",
            "Air Fryer, Chef's Knife, Blender Bottles, Vitamin Supplements\n",
            "Hello Eve Davis, based on your past purchases (Smartwatch) and interests in Tech, Fitness, we recommend the following products:\n",
            "Smart Home Devices, Wireless Earbuds, Yoga Mat, Resistance Bands\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello Eve Davis, based on your past purchases (Smartwatch) and interests in Tech, Fitness, we recommend the following products:\\nSmart Home Devices, Wireless Earbuds, Yoga Mat, Resistance Bands'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U_o453ABXOMp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}